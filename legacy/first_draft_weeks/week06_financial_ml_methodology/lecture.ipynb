{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 — Financial ML Methodology: Labeling, CV, and Backtesting\n",
    "\n",
    "**Course:** ML for Quantitative Finance  \n",
    "**Type:** Lecture (90 min)\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "This is what separates people who \"do ML\" from people who do ML **correctly** in finance.  \n",
    "Lopez de Prado's entire career is built on showing that **methodology matters more than models**.\n",
    "\n",
    "Three core problems:\n",
    "1. How to **label** financial data (triple-barrier method)\n",
    "2. How to **validate** without leaking information (purged k-fold)\n",
    "3. How to **combine** a primary model with a sizing model (meta-labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy = yf.download('SPY', start='2010-01-01', end='2024-12-31', progress=False)\n",
    "spy.columns = spy.columns.droplevel(1)\n",
    "spy['ret'] = spy['Close'].pct_change()\n",
    "spy['log_ret'] = np.log(spy['Close'] / spy['Close'].shift(1))\n",
    "spy = spy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Standard ML Methodology Fails in Finance\n",
    "\n",
    "### Problem 1: K-Fold CV Leaks Information\n",
    "- Financial data has serial correlation\n",
    "- Labels overlap (a 10-day return at $t$ shares 9 days with the return at $t+1$)\n",
    "- Shuffled k-fold puts overlapping samples in train AND test → information leakage\n",
    "\n",
    "### Problem 2: Fixed-Threshold Labeling Ignores Volatility\n",
    "- Labeling returns as +1 if $r > 0$ ignores that $r = 0.5\\%$ means very different things in a low-vol vs. high-vol regime\n",
    "- This creates class imbalance that shifts with market regimes\n",
    "\n",
    "### Problem 3: Backtesting ≠ Cross-Validation\n",
    "- Running 1000 backtests and picking the best one → you're overfitting to the backtest\n",
    "- The deflated Sharpe ratio corrects for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Triple-Barrier Labeling (Lopez de Prado Ch. 3)\n",
    "\n",
    "Three barriers that define each trade's outcome:\n",
    "1. **Profit-take barrier** (upper): price hits $+\\tau_{pt}$ → label = +1\n",
    "2. **Stop-loss barrier** (lower): price hits $-\\tau_{sl}$ → label = -1  \n",
    "3. **Time barrier** (vertical): max holding period expires → label = sign of return\n",
    "\n",
    "The barriers scale with **daily volatility**, making labels regime-adaptive.\n",
    "\n",
    "$$\\tau_{pt} = \\sigma_{daily} \\times \\text{multiplier}_{pt}$$\n",
    "$$\\tau_{sl} = \\sigma_{daily} \\times \\text{multiplier}_{sl}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_barrier_labels(prices, vol, pt_mult=2.0, sl_mult=2.0, max_holding=10):\n",
    "    \"\"\"Triple-barrier labeling.\n",
    "    \n",
    "    Args:\n",
    "        prices: Series of close prices\n",
    "        vol: Series of daily volatility (e.g., 20-day rolling std of returns)\n",
    "        pt_mult: profit-take multiplier × daily vol\n",
    "        sl_mult: stop-loss multiplier × daily vol\n",
    "        max_holding: maximum holding period in days\n",
    "    Returns:\n",
    "        DataFrame with columns: label, return, barrier_hit, end_date\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(prices) - max_holding):\n",
    "        entry_price = prices.iloc[i]\n",
    "        entry_date = prices.index[i]\n",
    "        daily_vol = vol.iloc[i]\n",
    "\n",
    "        if np.isnan(daily_vol) or daily_vol <= 0:\n",
    "            continue\n",
    "\n",
    "        pt = entry_price * (1 + pt_mult * daily_vol)\n",
    "        sl = entry_price * (1 - sl_mult * daily_vol)\n",
    "\n",
    "        # Check each day in the holding period\n",
    "        for j in range(1, max_holding + 1):\n",
    "            if i + j >= len(prices):\n",
    "                break\n",
    "            current_price = prices.iloc[i + j]\n",
    "\n",
    "            if current_price >= pt:\n",
    "                results.append({'date': entry_date, 'label': 1,\n",
    "                               'ret': (current_price - entry_price) / entry_price,\n",
    "                               'barrier': 'profit_take', 'days': j})\n",
    "                break\n",
    "            elif current_price <= sl:\n",
    "                results.append({'date': entry_date, 'label': -1,\n",
    "                               'ret': (current_price - entry_price) / entry_price,\n",
    "                               'barrier': 'stop_loss', 'days': j})\n",
    "                break\n",
    "        else:\n",
    "            # Time barrier hit\n",
    "            end_price = prices.iloc[i + max_holding]\n",
    "            ret = (end_price - entry_price) / entry_price\n",
    "            results.append({'date': entry_date, 'label': np.sign(ret),\n",
    "                           'ret': ret, 'barrier': 'time', 'days': max_holding})\n",
    "\n",
    "    return pd.DataFrame(results).set_index('date')\n",
    "\n",
    "\n",
    "# Apply to SPY\n",
    "vol = spy['ret'].rolling(20).std()\n",
    "labels = triple_barrier_labels(spy['Close'], vol, pt_mult=2.0, sl_mult=2.0, max_holding=10)\n",
    "\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"\\nBarrier distribution:\")\n",
    "print(labels['barrier'].value_counts())\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(labels['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to fixed-threshold labeling\n",
    "fixed_labels = np.sign(spy['Close'].pct_change(10).shift(-10)).dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(labels['ret'], bins=50, color='steelblue', edgecolor='white')\n",
    "axes[0].set_title(f'Triple-Barrier Returns\\n+1: {(labels[\"label\"]==1).mean():.0%}, -1: {(labels[\"label\"]==-1).mean():.0%}')\n",
    "\n",
    "axes[1].bar(['+1', '0', '-1'], [float((fixed_labels==1).mean()), float((fixed_labels==0).mean()), float((fixed_labels==-1).mean())], color='salmon')\n",
    "axes[1].set_title('Fixed Sign Labeling (10-day forward return)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Meta-Labeling (Lopez de Prado Ch. 3)\n",
    "\n",
    "**The idea:** Don't build one model. Build two:\n",
    "1. **Primary model:** Decides direction (buy/sell). Can be simple (e.g., MA crossover)\n",
    "2. **Meta-model:** Decides whether to *act* on the primary signal and *how much*\n",
    "\n",
    "The meta-model predicts: \"Given the primary model says BUY, will this trade be profitable?\"\n",
    "\n",
    "**Advantages:**\n",
    "- Primary model doesn't need to be perfect — just needs directional skill\n",
    "- Meta-model handles position sizing and risk management\n",
    "- Easier to interpret and debug than a single end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary model: SMA crossover (50/200)\n",
    "spy['sma_50'] = spy['Close'].rolling(50).mean()\n",
    "spy['sma_200'] = spy['Close'].rolling(200).mean()\n",
    "spy['signal'] = np.where(spy['sma_50'] > spy['sma_200'], 1, -1)\n",
    "\n",
    "# Generate triple-barrier labels for meta-labeling\n",
    "# Label = 1 if the primary model's trade was profitable\n",
    "meta_labels = labels.copy()\n",
    "common_idx = meta_labels.index.intersection(spy.index)\n",
    "meta_labels = meta_labels.loc[common_idx]\n",
    "\n",
    "# Meta-label: did the trade in the direction of the signal make money?\n",
    "primary_signal = spy.loc[common_idx, 'signal']\n",
    "meta_labels['meta_label'] = (meta_labels['ret'] * primary_signal > 0).astype(int)\n",
    "\n",
    "print(f\"Meta-labels: {len(meta_labels)}\")\n",
    "print(f\"Meta-label distribution (1=profitable trade):\")\n",
    "print(meta_labels['meta_label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Purged K-Fold Cross-Validation (Lopez de Prado Ch. 7)\n",
    "\n",
    "Standard k-fold leaks information when labels overlap. The fix:\n",
    "\n",
    "1. **Purge:** Remove training samples whose labels overlap with the test period\n",
    "2. **Embargo:** Add a gap between train and test to prevent leakage from any remaining serial correlation\n",
    "\n",
    "$$\\text{Embargo} \\geq \\text{max label duration}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurgedKFold:\n",
    "    \"\"\"Purged K-Fold CV for financial data.\"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5, embargo_days=10):\n",
    "        self.n_splits = n_splits\n",
    "        self.embargo_days = embargo_days\n",
    "\n",
    "    def split(self, dates):\n",
    "        \"\"\"Generate purged train/test indices.\n",
    "        \n",
    "        Args:\n",
    "            dates: array of datetime indices for each sample\n",
    "        Yields:\n",
    "            (train_indices, test_indices)\n",
    "        \"\"\"\n",
    "        unique_dates = np.sort(np.unique(dates))\n",
    "        fold_size = len(unique_dates) // self.n_splits\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            test_start = unique_dates[i * fold_size]\n",
    "            test_end = unique_dates[min((i + 1) * fold_size - 1, len(unique_dates) - 1)]\n",
    "\n",
    "            # Embargo: extend test period boundaries\n",
    "            embargo_start = test_start - pd.Timedelta(days=self.embargo_days)\n",
    "            embargo_end = test_end + pd.Timedelta(days=self.embargo_days)\n",
    "\n",
    "            test_mask = (dates >= test_start) & (dates <= test_end)\n",
    "            # Purge: remove training samples that overlap with test + embargo\n",
    "            train_mask = (dates < embargo_start) | (dates > embargo_end)\n",
    "\n",
    "            train_idx = np.where(train_mask)[0]\n",
    "            test_idx = np.where(test_mask)[0]\n",
    "\n",
    "            if len(train_idx) > 0 and len(test_idx) > 0:\n",
    "                yield train_idx, test_idx\n",
    "\n",
    "\n",
    "# Demonstrate information leakage\n",
    "# Compare standard k-fold vs purged k-fold on a simple model\n",
    "print(\"Purged K-Fold splits:\")\n",
    "pkf = PurgedKFold(n_splits=5, embargo_days=15)\n",
    "dates_arr = labels.index.values\n",
    "for fold, (train_idx, test_idx) in enumerate(pkf.split(dates_arr)):\n",
    "    print(f\"  Fold {fold}: train={len(train_idx)}, test={len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demonstrating Information Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create feature matrix for the meta-labeling problem\n",
    "feature_cols = ['ret', 'sma_50', 'sma_200']\n",
    "X_meta = spy.loc[meta_labels.index, ['ret']].copy()\n",
    "X_meta['vol'] = spy.loc[meta_labels.index, 'ret'].rolling(20).std()\n",
    "X_meta['mom'] = spy.loc[meta_labels.index, 'Close'].pct_change(20)\n",
    "X_meta['signal'] = spy.loc[meta_labels.index, 'signal']\n",
    "X_meta = X_meta.dropna()\n",
    "\n",
    "y_meta = meta_labels.loc[X_meta.index, 'meta_label']\n",
    "\n",
    "# Standard K-Fold (WRONG for financial data)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_standard = []\n",
    "for train_idx, test_idx in kf.split(X_meta):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    model.fit(X_meta.values[train_idx], y_meta.values[train_idx])\n",
    "    score = model.score(X_meta.values[test_idx], y_meta.values[test_idx])\n",
    "    scores_standard.append(score)\n",
    "\n",
    "# Purged K-Fold (CORRECT)\n",
    "pkf = PurgedKFold(n_splits=5, embargo_days=15)\n",
    "scores_purged = []\n",
    "for train_idx, test_idx in pkf.split(X_meta.index.values):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    model.fit(X_meta.values[train_idx], y_meta.values[train_idx])\n",
    "    score = model.score(X_meta.values[test_idx], y_meta.values[test_idx])\n",
    "    scores_purged.append(score)\n",
    "\n",
    "print(f\"Standard K-Fold accuracy: {np.mean(scores_standard):.3f} ± {np.std(scores_standard):.3f}\")\n",
    "print(f\"Purged K-Fold accuracy:   {np.mean(scores_purged):.3f} ± {np.std(scores_purged):.3f}\")\n",
    "print(f\"\\nDifference = {np.mean(scores_standard) - np.mean(scores_purged):.3f}\")\n",
    "print(\"This gap is the information leakage. Standard K-Fold overstates performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Triple-barrier labeling** adapts to volatility regimes. Fixed labels don't.\n",
    "2. **Meta-labeling** separates direction (primary model) from sizing (meta-model). More interpretable, more robust.\n",
    "3. **Purged k-fold** eliminates the information leakage that inflates standard CV scores.\n",
    "4. **The gap between standard and purged CV** tells you how much your model is cheating.\n",
    "5. **Methodology > models.** A Ridge with correct CV beats XGBoost with wrong CV.\n",
    "\n",
    "**Next week:** PyTorch fundamentals — transitioning from sklearn to neural networks for finance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}