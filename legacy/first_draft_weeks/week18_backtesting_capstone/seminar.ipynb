{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 14 — Seminar: Backtesting & Strategy Evaluation\n",
    "\n",
    "**Course:** ML for Quantitative Finance  \n",
    "**Type:** Seminar (90 min)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Deflated Sharpe Ratio (20 min)\n",
    "\n",
    "1. Implement the deflated Sharpe ratio function\n",
    "2. Generate 200 random strategies on real S&P 500 data\n",
    "3. Report the best Sharpe — then compute the DSR. Is it significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflated_sharpe_ratio(sharpe_obs, n_trials, T, skew=0, kurtosis=3):\n",
    "    \"\"\"Provided helper: compute DSR.\"\"\"\n",
    "    euler_mascheroni = 0.5772\n",
    "    sr0 = np.sqrt(2 * np.log(n_trials)) - (np.log(np.pi) + euler_mascheroni) / (2 * np.sqrt(2 * np.log(n_trials)))\n",
    "    se_sr = np.sqrt((1 + 0.5 * sharpe_obs**2 - skew * sharpe_obs +\n",
    "                     (kurtosis - 3) / 4 * sharpe_obs**2) / T)\n",
    "    z = (sharpe_obs - sr0) / se_sr\n",
    "    return stats.norm.cdf(z)\n",
    "\n",
    "\n",
    "# TODO: Download S&P 500 data (SPY)\n",
    "# TODO: Generate 200 random MA crossover strategies with random (fast, slow) params\n",
    "# TODO: Compute Sharpe for each\n",
    "# TODO: Report best Sharpe and its DSR\n",
    "# TODO: How many of the 200 strategies have DSR > 0.95?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Walk-Forward Backtest (30 min)\n",
    "\n",
    "1. Load 40 stocks, compute momentum/volatility features\n",
    "2. Implement walk-forward backtest with monthly rebalancing\n",
    "3. Compare: RF vs XGBoost, with and without transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\n",
    "    'AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'NVDA', 'JPM', 'JNJ', 'V', 'PG',\n",
    "    'UNH', 'HD', 'MA', 'DIS', 'BAC', 'XOM', 'CSCO', 'PFE', 'COST', 'ABT',\n",
    "    'PEP', 'AVGO', 'CRM', 'NKE', 'CVX', 'WMT', 'MRK', 'LLY', 'ABBV', 'INTC',\n",
    "    'T', 'VZ', 'QCOM', 'TXN', 'PM', 'UNP', 'NEE', 'LOW', 'BMY', 'AMGN',\n",
    "]\n",
    "\n",
    "cache_path = Path('w14_data_cache.pkl')\n",
    "if cache_path.exists():\n",
    "    raw = pd.read_pickle(cache_path)\n",
    "else:\n",
    "    raw = yf.download(TICKERS, start='2010-01-01', end='2024-12-31', progress=True)\n",
    "    raw.to_pickle(cache_path)\n",
    "\n",
    "prices = raw['Close'].ffill().dropna(axis=1, thresh=int(0.8 * len(raw)))\n",
    "returns_daily = prices.pct_change()\n",
    "monthly_prices = prices.resample('M').last()\n",
    "monthly_returns = monthly_prices.pct_change()\n",
    "\n",
    "# TODO: Compute features (mom_1m, mom_3m, mom_6m, vol_20d, vol_60d)\n",
    "# TODO: Build panel dataset\n",
    "# TODO: Walk-forward loop: for each month from 2016 onward,\n",
    "#   - train on expanding window\n",
    "#   - predict next month\n",
    "#   - form long-short quintile portfolio\n",
    "#   - record return (net of 10 bps/side costs)\n",
    "# TODO: Compare RF vs XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Full Tear Sheet (20 min)\n",
    "\n",
    "1. Implement a comprehensive tear sheet function\n",
    "2. Compute all key metrics: Sharpe, Sortino, Calmar, Max DD, VaR, CVaR, Tail Ratio\n",
    "3. Plot cumulative returns and drawdown chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement full_tear_sheet(returns_series) function\n",
    "# Should compute and print:\n",
    "#   - Annualized return and volatility\n",
    "#   - Sharpe, Sortino, Calmar ratios\n",
    "#   - Max drawdown\n",
    "#   - Hit rate and profit factor\n",
    "#   - VaR 5% and CVaR 5%\n",
    "#   - Skewness and kurtosis\n",
    "#   - Tail ratio (|95th pct / 5th pct|)\n",
    "# TODO: Plot cumulative returns + drawdown\n",
    "# TODO: Apply to your walk-forward results from Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion (20 min)\n",
    "\n",
    "1. Your walk-forward strategy has a Sharpe of X. If you tried 3 feature sets, 2 models, and 4 parameter configs (= 24 trials), what's the DSR?\n",
    "2. A hedge fund shows you a backtest with Sharpe 3.0 but won't tell you how many strategies they tested. What questions do you ask?\n",
    "3. Why do momentum strategies consistently work? Is this correlation or causation? What's the economic mechanism?\n",
    "4. Your strategy has great Sharpe but a Calmar of 0.3. Would you trade it with your own money? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}